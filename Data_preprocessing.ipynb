{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "uUkPpE699LBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This program module is designed for preprocessing textual reviews to prepare data for further analysis, including thematic classification and sentiment analysis. The main processing stages include text cleaning, stop-word removal, and lemmatization, which help standardize the text and improve the quality of subsequent processing using natural language processing (NLP) methods."
      ],
      "metadata": {
        "id": "PTHQbLRK9Q9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the code ready to work"
      ],
      "metadata": {
        "id": "DnLp04FV9bEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji\n",
        "!pip install language-tool-python\n",
        "!pip install nltk pymorphy3 language-tool-python beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOIs5Xgli2WN",
        "outputId": "026b02f1-72a1-468f-b3a1-a370871a120a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n",
            "Requirement already satisfied: language-tool-python in /usr/local/lib/python3.11/dist-packages (2.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (5.9.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2025.1.31)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.11/dist-packages (2.0.3)\n",
            "Requirement already satisfied: language-tool-python in /usr/local/lib/python3.11/dist-packages (2.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (2.4.417150.4580142)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.32.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (5.9.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pymorphy3 import MorphAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from datetime import datetime, timedelta\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Initializing tools\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "morph = MorphAnalyzer()\n",
        "russian_stopwords = set(stopwords.words('russian'))\n",
        "\n",
        "# A dictionary of months for date processing\n",
        "MONTHS = {\n",
        "    'января': 1, 'февраля': 2, 'марта': 3, 'апреля': 4,\n",
        "    'мая': 5, 'июня': 6, 'июля': 7, 'августа': 8,\n",
        "    'сентября': 9, 'октября': 10, 'ноября': 11, 'декабря': 12\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBjmptKM_to8",
        "outputId": "c03e5f20-07e7-4a21-f5f4-82e3a296f2ce"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing text"
      ],
      "metadata": {
        "id": "PH2AmSBU-Ibf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_russian_date(date_str):\n",
        "    \"\"\"Date parsing in Russian format with automatic year detection\"\"\"\n",
        "    if pd.isna(date_str) or not isinstance(date_str, str):\n",
        "        return pd.NaT\n",
        "    try:\n",
        "        parts = re.split(r'[\\s,.-]+', date_str.strip())\n",
        "        parts = [p for p in parts if p]\n",
        "        if len(parts) == 3:  # Full date (day, month, year)\n",
        "            day, month, year = parts\n",
        "            year = int(year)\n",
        "        elif len(parts) == 2:  # Only day and month\n",
        "            day, month = parts\n",
        "            current_date = datetime.now()\n",
        "            year = current_date.year\n",
        "            test_date = datetime(year, MONTHS[month.lower()], int(day))\n",
        "            if test_date > current_date:\n",
        "                year -= 1\n",
        "        else:\n",
        "            return pd.NaT\n",
        "        if month.lower() not in MONTHS:\n",
        "            return pd.NaT\n",
        "        return datetime(year, MONTHS[month.lower()], int(day))\n",
        "    except:\n",
        "        return pd.NaT\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clearing text with removal of stop words\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    try:\n",
        "        text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "        text = re.sub(r'[^а-яА-ЯёЁa-zA-Z .,!?]', ' ', text)\n",
        "        text = text.lower()\n",
        "        words = word_tokenize(text, language=\"russian\")\n",
        "        filtered_words = [word for word in words\n",
        "                        if word not in russian_stopwords\n",
        "                        and len(word) > 2\n",
        "                        and word.isalpha()]\n",
        "        return ' '.join(filtered_words)\n",
        "    except Exception as e:\n",
        "        print(f\"Error clearing text: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    \"\"\"Lemmatization of the text\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    try:\n",
        "        words = word_tokenize(text, language=\"russian\")\n",
        "        lemmas = [morph.parse(word)[0].normal_form for word in words]\n",
        "        return ' '.join(lemmas)\n",
        "    except Exception as e:\n",
        "        print(f\"Lemmatization error: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def process_reviews(input_file, output_file):\n",
        "    \"\"\"Main processing function\"\"\"\n",
        "    try:\n",
        "        # Reading data\n",
        "        df = pd.read_csv(input_file)\n",
        "        # Date processing\n",
        "        df['date_parsed'] = df['date'].progress_apply(parse_russian_date)\n",
        "\n",
        "        # Filtering by date (last six months)\n",
        "        cutoff_date = datetime.now() - timedelta(days=180)\n",
        "        df = df[df['date_parsed'] >= cutoff_date]\n",
        "\n",
        "        # Text processing\n",
        "        df['text_cleaned'] = df['review'].progress_apply(clean_text)\n",
        "        df['text_lemmatized'] = df['text_cleaned'].progress_apply(lemmatize_text)\n",
        "\n",
        "        # Deleting empty reviews\n",
        "        df = df[df['text_cleaned'].str.len() > 0]\n",
        "\n",
        "        # Formatting the result\n",
        "        df['date_formatted'] = df['date_parsed'].dt.strftime('%d.%m.%Y')\n",
        "        result_cols = ['date_formatted', 'rating', 'review', 'text_cleaned', 'text_lemmatized']\n",
        "\n",
        "        # Saving output\n",
        "        df[result_cols].to_csv(output_file, index=False, encoding='utf-8')\n",
        "\n",
        "        # Example data\n",
        "        if len(df) > 0:\n",
        "            print(\"\\nПример данных:\")\n",
        "            print(df[result_cols].head(3).to_markdown(index=False))\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка обработки: {e}\")\n",
        "        return pd.DataFrame()"
      ],
      "metadata": {
        "id": "TXxlEv1z_k7v"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXAMPLE\n",
        "if __name__ == \"__main__\":\n",
        "    input_csv = \"hotel_reviews_data.csv\"\n",
        "    output_csv = \"processed_reviews.csv\"\n",
        "    processed_data = process_reviews(input_csv, output_csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXhuwvYIA9iM",
        "outputId": "d226cb8a-9fbd-4132-ec2b-9dad2a813adb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Лемматизация: 100%|██████████| 18/18 [00:00<00:00, 12841.89it/s]\n",
            "Лемматизация: 100%|██████████| 12/12 [00:00<00:00, 1279.89it/s]\n",
            "Лемматизация: 100%|██████████| 12/12 [00:00<00:00, 265.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Пример данных:\n",
            "| date_formatted   |   rating | review                                                                                                                                                                                                                                                                                                                                                                           | text_cleaned                                                                                                                                                                                                                                                                                                             | text_lemmatized                                                                                                                                                                                                                                                                                                    |\n",
            "|:-----------------|---------:|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| 25.02.2025       |        2 | В номере воняет канализацией. Но персонал приветливый и вопросы решает.                                                                                                                                                                                                                                                                                                          | номере воняет канализацией персонал приветливый вопросы решает                                                                                                                                                                                                                                                           | номер вонять канализация персонал приветливый вопрос решать                                                                                                                                                                                                                                                        |\n",
            "| 25.02.2025       |        3 | Все бы хорошо но самое главное в номерах душно нужно продумать вопро о кондиционерах                                                                                                                                                                                                                                                                                             | самое главное номерах душно нужно продумать вопро кондиционерах                                                                                                                                                                                                                                                          | самый главное номер душный нужно продумать вопро кондиционер                                                                                                                                                                                                                                                       |\n",
            "| 30.09.2024       |        1 | Живу рядом с горным университетом. Руководство горного просто издевается над жителями. Блокирует проходы, делает самовольно платную парковку на территории жк, их про-горная управляющая компания дерёт немалые деньги за обслуживание, но ничего не делает. Ректор горного самый богатый человек спб) не хватит слов передать как мы их ненавидим. Коррумпированный университет | живу рядом горным университетом руководство горного просто издевается жителями блокирует проходы делает самовольно платную парковку территории горная управляющая компания дерёт немалые деньги обслуживание делает ректор горного самый богатый человек спб хватит слов передать ненавидим коррумпированный университет | жить рядом горный университет руководство горный просто издеваться житель блокировать проход делать самовольно платный парковка территория горный управлять компания драть немалый деньга обслуживание делать ректор горный самый богатый человек спб хватить слово передать ненавидеть коррумпировать университет |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}